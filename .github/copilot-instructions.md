# Copilot Instructions for Risk-Metrics-Analyst-Agent
- **Architecture:** `app_main.py` bootstraps Streamlit and delegates to `risk_metrics_app.run_app()`. The package splits responsibilities across `app.py` (UI flow), `metrics.py` (data prep/stats), `visuals.py` (Plotly), `llm.py` (Gemini orchestration), `reporting.py` (exports), `extraction.py` (mock API fetch), and `config.py` (paths/logging/constants).
- **Runbook:** `python -m venv .venv; .\.venv\Scripts\Activate.ps1; pip install -r requirements.txt; streamlit run app_main.py`. The app expects Windows-friendly paths and writes artifacts to `Output/`.
- **API key handling:** The sidebar text box stores the provided key in `os.environ['GOOGLE_API_KEY']`. Any automation must set this env var or override the `ChatGoogleGenerativeAI` factory before invoking LLM helpers.
- **Data ingestion contract:** Uploaded CSV columns are lower-cased (`handle_analysis` mutates `df.columns`), so ensure a case-insensitive `ValueDate` column plus numeric metric columns. Optional limit columns must follow the suffixes `_limMaxValue`/`_limMinValue` (matching case-insensitive check after lower-casing).
- **Batch processing (001-batch-viz-enhance):** When `stranaNodeName` column detected (case-insensitive via `detect_node_column`), batch mode splits data via `split_by_node`. Results stored in `st.session_state.batch_results` keyed by node name. UI displays via `st.tabs()` with one tab per node. Exports use node-folder structure (`/{NodeA}/report.html`, `/{NodeA}/charts/`).
- **Adaptive scaling (001-batch-viz-enhance):** `calculate_scale_context` detects when data occupies <10% of y-axis range due to large limits. When triggered, charts zoom to data range and display limit annotation banner via `create_limit_annotation_html` showing limit values grouped by time period.
- **Data interpolation (001-batch-viz-enhance):** `interpolate_for_display` uses pandas `interpolate(method='time')` to fill systematic gaps for chart display. Statistics always use original (non-interpolated) data from `InterpolatedSeries.original`.
- **Metric ordering:** `metrics.PRIORITY_METRICS = ['VaR','SVaR','STTHH']` are surfaced first. Remaining columns are parsed via `parse_metric_name` to split maturity tokens (e.g., `1W`, `1M`, `2Y`) and sorted with `get_maturity_order`; extend these helpers when onboarding new headline metrics or naming schemes.
- **Statistics & outliers:** `calculate_statistics` returns `mean/median/std/min/max/count` and flags ±2σ outliers. Downstream UI, exports, and prompt builders assume these keys; preserve them and keep series indices aligned with `df[valuedate]` for outlier/date joins.
- **Limit checks:** `check_limit_breaches` compares metric values to optional limit Series, returning dictionaries with `type/count/dates`. Maintain identical indexing and date formatting to keep both UI warnings and export text consistent.
- **Chart pipeline:** `create_plotly_chart` overlays mean/median/limits/outliers on a single figure (no legend shown). Accepts optional `scale_context` for adaptive scaling and `display_series` for interpolated data. `save_and_encode_image` persists PNGs to `Output/` using Kaleido before base64 encoding; ensure `kaleido` remains installed and writable paths exist.
- **LLM workflow:** `process_llm_requests` batches `ChatGoogleGenerativeAI(model='gemini-flash-lite-latest')` calls with asyncio semaphores (`MAX_LLM_CONCURRENCY`, retries from `config.py`). Errors are surfaced as `"Error generating ..."` strings; keep that contract for UI messaging.
- **Prompt expectations:** `create_llm_prompt` and `create_portfolio_summary_prompt` emit highly-structured instructions consumed by Gemini. Preserve section headers, paragraph counts, and XML-like wrappers when adjusting copy so existing parsing assumptions remain valid.
- **Session state:** `initialize_session_state` seeds keys such as `metrics_analyses`, `portfolio_summary`, `analysis_completed`, and extraction form fields. Batch mode adds `batch_mode`, `batch_results`, `batch_node_names`, `batch_portfolio_summaries`, `scale_contexts`, `adaptive_scale_toggles`. Add new features by extending this setup and storing results in session state to survive Streamlit reruns.
- **AI skip logic:** Metrics with ≥95% zeroes skip LLM analysis (`insights` defaults to "Low exposure, no insight"); downstream reporting expects a non-null string, so respect this guard when changing metric handling.
- **Exports:** `create_html_report` renders Plotly figures via `to_html` and injects stats/breach/outlier text; `create_export_package` bundles that HTML, per-metric PNGs (`pio.to_image`), and `summary.txt`. Batch mode uses `create_batch_export_package` for node-folder ZIP structure.
- **API extraction tab:** `render_extraction_tab` calls `extract_data_via_proxy`, which builds deterministic CSVs in `Output/` and validates username/password/perimeters plus optional `start_date`/`end_date` (both-or-neither). Update `_build_proxy_dataset` when the mock payload shape changes.
- **Logging & diagnostics:** `config.setup_logging` writes to `risk_metrics_app/risk_metrics_analysis.log`; call `logger` for any new background work. Generated CSV/PNG paths are surfaced in the UI for manual inspection.
- **Reference assets:** Use `Examples/Fake Pivot Metrics.csv` for smoke tests (contains `stranaNodeName` with "a" and "b" nodes). Charts and extracts appear under `Output/`, which is git-ignored—check there for troubleshooting generated artifacts.
- **Testing posture:** No automated tests exist; validate changes manually by running `streamlit run app_main.py`, uploading the sample CSV, toggling multi-metric flows, batch mode, adaptive scaling, exports, and the API extraction form.
